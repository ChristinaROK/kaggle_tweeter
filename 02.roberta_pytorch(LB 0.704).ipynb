{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Info\n",
    "## kaggle\n",
    "[current kaggle kernel](https://www.kaggle.com/enzoamp/commented-roberta-training-with-pytorch)\n",
    "\n",
    "## description\n",
    "- ensemble은 사용하지 않았음 (-> ensemble 할 것)\n",
    "- Perceptron layer 사용 (-> cnn layer?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "import transformers\n",
    "import tokenizers\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from tqdm.autonotebook import tqdm\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `input_ids` = [0 + SENTIMENT_ID + 2 + 2 + TEXT_IDS + 2 + 1....] (`0` == CLS, `2` == SEP, `1` == 공백 string)\n",
    "- `attention_mask` = (TEXT_IDS + 5)가 1\n",
    "- `token_type_ids`\n",
    "- `start_tokens` = selected_text 시작 index\n",
    "- `end_tokens` = selected_text 끝 index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROBERTA_PATH = './roberta/'\n",
    "MAX_LEN = 96 # 192는 뭐야? \n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 8\n",
    "EPOCHS = 5\n",
    "TRAINING_FILE = './train_folds.csv'\n",
    "TOKENIZER = tokenizers.ByteLevelBPETokenizer(\n",
    "    vocab_file=ROBERTA_PATH+'vocab.json', \n",
    "    merges_file=ROBERTA_PATH+'merges.txt', \n",
    "    lowercase=True,\n",
    "    add_prefix_space=True\n",
    ")\n",
    "sentiment_id = {'positive': 1313, 'negative': 2430, 'neutral': 7974}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(tweet, selected_text, sentiment, tokenizer, max_len):\n",
    "    \"\"\"\n",
    "    Processes the tweet and outputs the features necessary for model training and inference.\n",
    "    \n",
    "    Note: there are some differences between this and the BERT version (bert-case-uncased), mostly due to differences in token codes and special tokens\n",
    "    \"\"\"\n",
    "    tweet = \" \" + \" \".join(str(tweet).split())\n",
    "    selected_text = \" \" + \" \".join(str(selected_text).split())\n",
    "\n",
    "    len_st = len(selected_text) - 1\n",
    "    idx0 = None\n",
    "    idx1 = None\n",
    "\n",
    "    for ind in (i for i, e in enumerate(tweet) if e == selected_text[1]):\n",
    "        if \" \" + tweet[ind: ind+len_st] == selected_text:\n",
    "            idx0 = ind\n",
    "            idx1 = ind + len_st - 1\n",
    "            break\n",
    "\n",
    "    char_targets = [0] * len(tweet)\n",
    "    if idx0 != None and idx1 != None:\n",
    "        for ct in range(idx0, idx1 + 1):\n",
    "            char_targets[ct] = 1\n",
    "    \n",
    "    tok_tweet = tokenizer.encode(tweet)\n",
    "    input_ids_orig = tok_tweet.ids\n",
    "    tweet_offsets = tok_tweet.offsets\n",
    "    \n",
    "    target_idx = []\n",
    "    for j, (offset1, offset2) in enumerate(tweet_offsets):\n",
    "        if sum(char_targets[offset1: offset2]) > 0:\n",
    "            target_idx.append(j)\n",
    "    \n",
    "    targets_start = target_idx[0]\n",
    "    targets_end = target_idx[-1]\n",
    "\n",
    "    sentiment_id = {\n",
    "        'positive': 1313,\n",
    "        'negative': 2430,\n",
    "        'neutral': 7974\n",
    "    }\n",
    "    \n",
    "    input_ids = [0] + [sentiment_id[sentiment]] + [2] + [2] + input_ids_orig + [2]\n",
    "    token_type_ids = [0, 0, 0, 0] + [0] * (len(input_ids_orig) + 1)\n",
    "    mask = [1] * len(token_type_ids)\n",
    "    tweet_offsets = [(0, 0)] * 4 + tweet_offsets + [(0, 0)]\n",
    "    targets_start += 4\n",
    "    targets_end += 4\n",
    "\n",
    "    padding_length = max_len - len(input_ids)\n",
    "    if padding_length > 0:\n",
    "        input_ids = input_ids + ([1] * padding_length)\n",
    "        mask = mask + ([0] * padding_length)\n",
    "        token_type_ids = token_type_ids + ([0] * padding_length)\n",
    "        tweet_offsets = tweet_offsets + ([(0, 0)] * padding_length)\n",
    "    \n",
    "    return {\n",
    "        'ids': input_ids,\n",
    "        'mask': mask,\n",
    "        'token_type_ids': token_type_ids,\n",
    "        'targets_start': targets_start,\n",
    "        'targets_end': targets_end,\n",
    "        'orig_tweet': tweet,\n",
    "        'orig_selected': selected_text,\n",
    "        'sentiment': sentiment,\n",
    "        'offsets': tweet_offsets\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show me example\n",
    "dfx = pd.read_csv(TRAINING_FILE)\n",
    "fold = 0\n",
    "\n",
    "# 5 folds \n",
    "df_train = dfx[dfx.kfold != fold].reset_index(drop=True)\n",
    "df_valid = dfx[dfx.kfold == fold].reset_index(drop=True)\n",
    "\n",
    "pre_dict = process_data(df_train.iloc[:1,:]['text'][0], df_train.iloc[:1,:]['selected_text'][0], df_train.iloc[:1,:]['sentiment'][0], TOKENIZER, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_dict['targets_end']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ġthought',\n",
       " 'Ġyes',\n",
       " 'Ġman',\n",
       " 'Ġwas',\n",
       " 'Ġgood',\n",
       " 'Ġ',\n",
       " 'Ġhad',\n",
       " 'Ġa',\n",
       " 'Ġblast',\n",
       " 'Ġwith',\n",
       " 'Ġold',\n",
       " 'Ġfriends',\n",
       " 'Ġtonight',\n",
       " 'Ġand',\n",
       " 'Ġheard',\n",
       " 'Ġsome',\n",
       " 'Ġgreat',\n",
       " 'Ġmusic']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKENIZER.encode(df_train.iloc[:1,:]['text'][0]).tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetDataset:\n",
    "    \"\"\"\n",
    "    Dataset which stores the tweets and returns them as processed features\n",
    "    \"\"\"\n",
    "    def __init__(self, tweet, sentiment, selected_text):\n",
    "        self.tweet = tweet\n",
    "        self.sentiment = sentiment\n",
    "        self.selected_text = selected_text\n",
    "        self.tokenizer = TOKENIZER\n",
    "        self.max_len = MAX_LEN\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tweet)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        data = process_data(\n",
    "            self.tweet[item], \n",
    "            self.selected_text[item], \n",
    "            self.sentiment[item],\n",
    "            self.tokenizer,\n",
    "            self.max_len\n",
    "        )\n",
    "\n",
    "        # Return the processed data where the lists are converted to `torch.tensor`s\n",
    "        return {\n",
    "            'ids': torch.tensor(data[\"ids\"], dtype=torch.long),\n",
    "            'mask': torch.tensor(data[\"mask\"], dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(data[\"token_type_ids\"], dtype=torch.long),\n",
    "            'targets_start': torch.tensor(data[\"targets_start\"], dtype=torch.long),\n",
    "            'targets_end': torch.tensor(data[\"targets_end\"], dtype=torch.long),\n",
    "            'orig_tweet': data[\"orig_tweet\"],\n",
    "            'orig_selected': data[\"orig_selected\"],\n",
    "            'sentiment': data[\"sentiment\"],\n",
    "            'offsets': torch.tensor(data[\"offsets\"], dtype=torch.long)\n",
    "        }\n",
    "    \n",
    "class TweetModel(transformers.BertPreTrainedModel):\n",
    "    \"\"\"\n",
    "    Model class that combines a pretrained bert model with a linear later\n",
    "    \"\"\"\n",
    "    def __init__(self, conf):\n",
    "        super(TweetModel, self).__init__(conf)\n",
    "        # Load the pretrained BERT model\n",
    "        self.roberta = transformers.RobertaModel.from_pretrained(ROBERTA_PATH, config=conf)\n",
    "        # Set 10% dropout to be applied to the BERT backbone's output\n",
    "        self.drop_out = nn.Dropout(0.1)\n",
    "        # 768 is the dimensionality of bert-base-uncased's hidden representations\n",
    "        # Multiplied by 2 since the forward pass concatenates the last two hidden representation layers\n",
    "        # The output will have two dimensions (\"start_logits\", and \"end_logits\")\n",
    "        self.l0 = nn.Linear(768 * 2, 2)\n",
    "        torch.nn.init.normal_(self.l0.weight, std=0.02)\n",
    "    \n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        # Return the hidden states from the BERT backbone\n",
    "        _, _, out = self.roberta(\n",
    "            ids,\n",
    "            attention_mask=mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        ) # bert_layers x bs x SL x (768 * 2)\n",
    "\n",
    "        # Concatenate the last two hidden states\n",
    "        # This is done since experiments have shown that just getting the last layer\n",
    "        # gives out vectors that may be too taylored to the original BERT training objectives (MLM + NSP)\n",
    "        # Sample explanation: https://bert-as-service.readthedocs.io/en/latest/section/faq.html#why-not-the-last-hidden-layer-why-second-to-last\n",
    "        out = torch.cat((out[-1], out[-2]), dim=-1) # bs x SL x (768 * 2)\n",
    "        # Apply 10% dropout to the last 2 hidden states\n",
    "        out = self.drop_out(out) # bs x SL x (768 * 2)\n",
    "        # The \"dropped out\" hidden vectors are now fed into the linear layer to output two scores\n",
    "        logits = self.l0(out) # bs x SL x 2\n",
    "\n",
    "        # Splits the tensor into start_logits and end_logits\n",
    "        # (bs x SL x 2) -> (bs x SL x 1), (bs x SL x 1)\n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "\n",
    "        start_logits = start_logits.squeeze(-1) # (bs x SL)\n",
    "        end_logits = end_logits.squeeze(-1) # (bs x SL)\n",
    "\n",
    "        return start_logits, end_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(start_logits, end_logits, start_positions, end_positions):\n",
    "    \"\"\"\n",
    "    Return the sum of the cross entropy losses for both the start and end logits\n",
    "    \"\"\"\n",
    "    loss_fct = nn.CrossEntropyLoss()\n",
    "    start_loss = loss_fct(start_logits, start_positions)\n",
    "    end_loss = loss_fct(end_logits, end_positions)\n",
    "    total_loss = (start_loss + end_loss)\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. Train_fn, Eval_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(data_loader, model, optimizer, device, scheduler=None):\n",
    "    \"\"\"\n",
    "    Trains the bert model on the twitter data\n",
    "    \"\"\"\n",
    "    # Set model to training mode (dropout + sampled batch norm is activated)\n",
    "    model.train()\n",
    "    losses = utils.AverageMeter()\n",
    "    jaccards = utils.AverageMeter()\n",
    "\n",
    "    # Set tqdm to add loading screen and set the length\n",
    "    tk0 = tqdm(data_loader, total=len(data_loader))\n",
    "    \n",
    "    # Train the model on each batch\n",
    "    for bi, d in enumerate(tk0):\n",
    "\n",
    "        ids = d[\"ids\"]\n",
    "        token_type_ids = d[\"token_type_ids\"]\n",
    "        mask = d[\"mask\"]\n",
    "        targets_start = d[\"targets_start\"]\n",
    "        targets_end = d[\"targets_end\"]\n",
    "        sentiment = d[\"sentiment\"]\n",
    "        orig_selected = d[\"orig_selected\"]\n",
    "        orig_tweet = d[\"orig_tweet\"]\n",
    "        targets_start = d[\"targets_start\"]\n",
    "        targets_end = d[\"targets_end\"]\n",
    "        offsets = d[\"offsets\"]\n",
    "        \n",
    "\n",
    "        # Move ids, masks, and targets to gpu while setting as torch.long\n",
    "        ids = ids.to(device, dtype=torch.long)\n",
    "        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "        mask = mask.to(device, dtype=torch.long)\n",
    "        targets_start = targets_start.to(device, dtype=torch.long)\n",
    "        targets_end = targets_end.to(device, dtype=torch.long)\n",
    "\n",
    "        # Reset gradients\n",
    "        model.zero_grad()\n",
    "        # Use ids, masks, and token types as input to the model\n",
    "        # Predict logits for each of the input tokens for each batch\n",
    "        outputs_start, outputs_end = model(\n",
    "            ids=ids,\n",
    "            mask=mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "        ) # (bs x SL), (bs x SL)\n",
    "        # Calculate batch loss based on CrossEntropy\n",
    "        loss = loss_fn(outputs_start, outputs_end, targets_start, targets_end)\n",
    "        # Calculate gradients based on loss\n",
    "        loss.backward()\n",
    "        # Adjust weights based on calculated gradients\n",
    "        optimizer.step()\n",
    "        # Update scheduler\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Apply softmax to the start and end logits\n",
    "        # This squeezes each of the logits in a sequence to a value between 0 and 1, while ensuring that they sum to 1\n",
    "        # This is similar to the characteristics of \"probabilities\"\n",
    "        outputs_start = torch.softmax(outputs_start, dim=1).cpu().detach().numpy()\n",
    "        outputs_end = torch.softmax(outputs_end, dim=1).cpu().detach().numpy()\n",
    "        \n",
    "        # Calculate the jaccard score based on the predictions for this batch\n",
    "        jaccard_scores = []\n",
    "        for px, tweet in enumerate(orig_tweet):\n",
    "            selected_tweet = orig_selected[px]\n",
    "            tweet_sentiment = sentiment[px]\n",
    "            jaccard_score, _ = calculate_jaccard_score(\n",
    "                original_tweet=tweet, # Full text of the px'th tweet in the batch\n",
    "                target_string=selected_tweet, # Span containing the specified sentiment for the px'th tweet in the batch\n",
    "                sentiment_val=tweet_sentiment, # Sentiment of the px'th tweet in the batch\n",
    "                idx_start=np.argmax(outputs_start[px, :]), # Predicted start index for the px'th tweet in the batch\n",
    "                idx_end=np.argmax(outputs_end[px, :]), # Predicted end index for the px'th tweet in the batch\n",
    "                offsets=offsets[px] # Offsets for each of the tokens for the px'th tweet in the batch\n",
    "            )\n",
    "            jaccard_scores.append(jaccard_score)\n",
    "        # Update the jaccard score and loss\n",
    "        # For details, refer to `AverageMeter` in https://www.kaggle.com/abhishek/utils\n",
    "        jaccards.update(np.mean(jaccard_scores), ids.size(0))\n",
    "        losses.update(loss.item(), ids.size(0))\n",
    "        # Print the average loss and jaccard score at the end of each batch\n",
    "        tk0.set_postfix(loss=losses.avg, jaccard=jaccards.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_jaccard_score(\n",
    "    original_tweet, \n",
    "    target_string, \n",
    "    sentiment_val, \n",
    "    idx_start, \n",
    "    idx_end, \n",
    "    offsets,\n",
    "    verbose=False):\n",
    "    \"\"\"\n",
    "    Calculate the jaccard score from the predicted span and the actual span for a batch of tweets\n",
    "    \"\"\"\n",
    "    \n",
    "    # A span's start index has to be greater than or equal to the end index\n",
    "    # If this doesn't hold, the start index is set to equal the end index (the span is a single token)\n",
    "    if idx_end < idx_start:\n",
    "        idx_end = idx_start\n",
    "    \n",
    "    # Combine into a string the tokens that belong to the predicted span\n",
    "    filtered_output  = \"\"\n",
    "    for ix in range(idx_start, idx_end + 1):\n",
    "        filtered_output += original_tweet[offsets[ix][0]: offsets[ix][1]]\n",
    "        # If the token is not the last token in the tweet, and the ending offset of the current token is less\n",
    "        # than the beginning offset of the following token, add a space.\n",
    "        # Basically, add a space when the next token (word piece) corresponds to a new word\n",
    "        if (ix+1) < len(offsets) and offsets[ix][1] < offsets[ix+1][0]:\n",
    "            filtered_output += \" \"\n",
    "\n",
    "    # Set the predicted output as the original tweet when the tweet's sentiment is \"neutral\", or the tweet only contains one word\n",
    "    if sentiment_val == \"neutral\" or len(original_tweet.split()) < 2:\n",
    "        filtered_output = original_tweet\n",
    "\n",
    "    # Calculate the jaccard score between the predicted span, and the actual span\n",
    "    # The IOU (intersection over union) approach is detailed in the utils module's `jaccard` function:\n",
    "    # https://www.kaggle.com/abhishek/utils\n",
    "    jac = utils.jaccard(target_string.strip(), filtered_output.strip())\n",
    "    return jac, filtered_output\n",
    "\n",
    "\n",
    "def eval_fn(data_loader, model, device):\n",
    "    \"\"\"\n",
    "    Evaluation function to predict on the test set\n",
    "    \"\"\"\n",
    "    # Set model to evaluation mode\n",
    "    # I.e., turn off dropout and set batchnorm to use overall mean and variance (from training), rather than batch level mean and variance\n",
    "    # Reference: https://github.com/pytorch/pytorch/issues/5406\n",
    "    model.eval()\n",
    "    losses = utils.AverageMeter()\n",
    "    jaccards = utils.AverageMeter()\n",
    "    \n",
    "    # Turns off gradient calculations (https://datascience.stackexchange.com/questions/32651/what-is-the-use-of-torch-no-grad-in-pytorch)\n",
    "    with torch.no_grad():\n",
    "        tk0 = tqdm(data_loader, total=len(data_loader))\n",
    "        # Make predictions and calculate loss / jaccard score for each batch\n",
    "        for bi, d in enumerate(tk0):\n",
    "            ids = d[\"ids\"]\n",
    "            token_type_ids = d[\"token_type_ids\"]\n",
    "            mask = d[\"mask\"]\n",
    "            sentiment = d[\"sentiment\"]\n",
    "            orig_selected = d[\"orig_selected\"]\n",
    "            orig_tweet = d[\"orig_tweet\"]\n",
    "            targets_start = d[\"targets_start\"]\n",
    "            targets_end = d[\"targets_end\"]\n",
    "            offsets = d[\"offsets\"].numpy()\n",
    "            \n",
    "            # Move ids, masks, and targets to gpu while setting as torch.long\n",
    "            ids = ids.to(device, dtype=torch.long)\n",
    "            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "            mask = mask.to(device, dtype=torch.long)\n",
    "            targets_start = targets_start.to(device, dtype=torch.long)\n",
    "            targets_end = targets_end.to(device, dtype=torch.long)\n",
    "\n",
    "            # Move tensors to GPU for faster matrix calculations\n",
    "            ids = ids.to(device, dtype=torch.long)\n",
    "            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "            mask = mask.to(device, dtype=torch.long)\n",
    "            targets_start = targets_start.to(device, dtype=torch.long)\n",
    "            targets_end = targets_end.to(device, dtype=torch.long)\n",
    "\n",
    "            # Predict logits for start and end indexes\n",
    "            outputs_start, outputs_end = model(\n",
    "                ids=ids,\n",
    "                mask=mask,\n",
    "                token_type_ids=token_type_ids\n",
    "            )\n",
    "            # Calculate loss for the batch\n",
    "            loss = loss_fn(outputs_start, outputs_end, targets_start, targets_end)\n",
    "            # Apply softmax to the predicted logits for the start and end indexes\n",
    "            # This converts the \"logits\" to \"probability-like\" scores\n",
    "            outputs_start = torch.softmax(outputs_start, dim=1).cpu().detach().numpy()\n",
    "            outputs_end = torch.softmax(outputs_end, dim=1).cpu().detach().numpy()\n",
    "            # Calculate jaccard scores for each tweet in the batch\n",
    "            jaccard_scores = []\n",
    "            for px, tweet in enumerate(orig_tweet):\n",
    "                selected_tweet = orig_selected[px]\n",
    "                tweet_sentiment = sentiment[px]\n",
    "                jaccard_score, _ = calculate_jaccard_score(\n",
    "                    original_tweet=tweet,\n",
    "                    target_string=selected_tweet,\n",
    "                    sentiment_val=tweet_sentiment,\n",
    "                    idx_start=np.argmax(outputs_start[px, :]),\n",
    "                    idx_end=np.argmax(outputs_end[px, :]),\n",
    "                    offsets=offsets[px]\n",
    "                )\n",
    "                jaccard_scores.append(jaccard_score)\n",
    "\n",
    "            # Update running jaccard score and loss\n",
    "            jaccards.update(np.mean(jaccard_scores), ids.size(0))\n",
    "            losses.update(loss.item(), ids.size(0))\n",
    "            # Print the running average loss and jaccard score\n",
    "            tk0.set_postfix(loss=losses.avg, jaccard=jaccards.avg)\n",
    "    \n",
    "    print(f\"Jaccard = {jaccards.avg}\")\n",
    "    return jaccards.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(fold):\n",
    "    \"\"\"\n",
    "    Train model for a speciied fold\n",
    "    \"\"\"\n",
    "    # Read training csv\n",
    "    dfx = pd.read_csv(TRAINING_FILE)\n",
    "\n",
    "    # Set train validation set split\n",
    "    df_train = dfx[dfx.kfold != fold].reset_index(drop=True)\n",
    "    df_valid = dfx[dfx.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "    # Instantiate TweetDataset with training data\n",
    "    train_dataset = TweetDataset(\n",
    "        tweet=df_train.text.values,\n",
    "        sentiment=df_train.sentiment.values,\n",
    "        selected_text=df_train.selected_text.values\n",
    "    )\n",
    "\n",
    "    # Instantiate DataLoader with `train_dataset`\n",
    "    # This is a generator that yields the dataset in batches\n",
    "    train_data_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=TRAIN_BATCH_SIZE,\n",
    "        num_workers=4\n",
    "    )\n",
    "\n",
    "    # Instantiate TweetDataset with validation data\n",
    "    valid_dataset = TweetDataset(\n",
    "        tweet=df_valid.text.values,\n",
    "        sentiment=df_valid.sentiment.values,\n",
    "        selected_text=df_valid.selected_text.values\n",
    "    )\n",
    "\n",
    "    # Instantiate DataLoader with `valid_dataset`\n",
    "    valid_data_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=VALID_BATCH_SIZE,\n",
    "        num_workers=2\n",
    "    )\n",
    "\n",
    "    # Set device as `cuda` (GPU)\n",
    "    device = torch.device(\"cuda\")\n",
    "    # Load pretrained RoBERTa\n",
    "    model_config = transformers.RobertaConfig.from_pretrained(ROBERTA_PATH)\n",
    "    # Output hidden states\n",
    "    # This is important to set since we want to concatenate the hidden states from the last 2 BERT layers\n",
    "    model_config.output_hidden_states = True\n",
    "    # Instantiate our model with `model_config`\n",
    "    model = TweetModel(conf=model_config)\n",
    "    # Move the model to the GPU\n",
    "    model.to(device)\n",
    "\n",
    "    # Calculate the number of training steps\n",
    "    num_train_steps = int(len(df_train) / TRAIN_BATCH_SIZE * EPOCHS)\n",
    "    # Get the list of named parameters\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    # Specify parameters where weight decay shouldn't be applied\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    # Define two sets of parameters: those with weight decay, and those without\n",
    "    optimizer_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n",
    "    ]\n",
    "    # Instantiate AdamW optimizer with our two sets of parameters, and a learning rate of 3e-5\n",
    "    optimizer = AdamW(optimizer_parameters, lr=3e-5)\n",
    "    # Create a scheduler to set the learning rate at each training step\n",
    "    # \"Create a schedule with a learning rate that decreases linearly after linearly increasing during a warmup period.\" (https://pytorch.org/docs/stable/optim.html)\n",
    "    # Since num_warmup_steps = 0, the learning rate starts at 3e-5, and then linearly decreases at each training step\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, \n",
    "        num_warmup_steps=0, \n",
    "        num_training_steps=num_train_steps\n",
    "    )\n",
    "\n",
    "    # Apply early stopping with patience of 2\n",
    "    # This means to stop training new epochs when 2 rounds have passed without any improvement\n",
    "    es = utils.EarlyStopping(patience=2, mode=\"max\")\n",
    "    print(f\"Training is Starting for fold={fold}\")\n",
    "    \n",
    "    # I'm training only for 3 epochs even though I specified 5!!!\n",
    "    for epoch in range(3):\n",
    "        train_fn(train_data_loader, model, optimizer, device, scheduler=scheduler)\n",
    "        jaccard = eval_fn(valid_data_loader, model, device)\n",
    "        print(f\"Jaccard Score = {jaccard}\")\n",
    "        es(jaccard, model, model_path=ROBERTA_PATH + f\"model_{fold}.bin\")\n",
    "        if es.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is Starting for fold=0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f158b0265cf74c88a6ecc7f9f8b9425d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "571abd6d2287461fb22890b84f052639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard = 0.6861462074987804\n",
      "Jaccard Score = 0.6861462074987804\n",
      "Validation score improved (-inf --> 0.6861462074987804). Saving model!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f91589780524a38a0d862065c1f9236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "760702cdeb974eb3be75f11b90a2788a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard = 0.6988356292634424\n",
      "Jaccard Score = 0.6988356292634424\n",
      "Validation score improved (0.6861462074987804 --> 0.6988356292634424). Saving model!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f2e49b210664a6e8a18f91ed021e601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6b3afe4c65442c79b2d9576ac6832e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard = 0.7004398418027226\n",
      "Jaccard Score = 0.7004398418027226\n",
      "Validation score improved (0.6988356292634424 --> 0.7004398418027226). Saving model!\n"
     ]
    }
   ],
   "source": [
    "run(fold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test.csv')\n",
    "df_test['selected_text'] = df_test.text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model_config = transformers.RobertaConfig.from_pretrained(ROBERTA_PATH)\n",
    "model_config.output_hidden_states = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TweetModel(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (drop_out): Dropout(p=0.1)\n",
       "  (l0): Linear(in_features=1536, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "model1 = TweetModel(conf = model_config)\n",
    "model1.to(device)\n",
    "model1.load_state_dict(torch.load('model_0.bin'))\n",
    "model1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9e6dbba74034439917ca4448ea59194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=442.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "final_output = []\n",
    "\n",
    "# Instantiate\n",
    "test_dataset = TweetDataset(tweet=df_test.text.values,\n",
    "                           sentiment = df_test.sentiment.values,\n",
    "                           selected_text=df_test.selected_text.values)\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                         shuffle = False,\n",
    "                                         batch_size=VALID_BATCH_SIZE,\n",
    "                                         num_workers=1)\n",
    "with torch.no_grad():\n",
    "    tk0 = tqdm(data_loader, total=len(data_loader))\n",
    "    # Predict the span containing the sentiment for each batch\n",
    "    for bi, d in enumerate(tk0):\n",
    "        ids = d[\"ids\"]\n",
    "        token_type_ids = d[\"token_type_ids\"]\n",
    "        mask = d[\"mask\"]\n",
    "        sentiment = d[\"sentiment\"]\n",
    "        orig_selected = d[\"orig_selected\"]\n",
    "        orig_tweet = d[\"orig_tweet\"]\n",
    "        targets_start = d[\"targets_start\"]\n",
    "        targets_end = d[\"targets_end\"]\n",
    "        offsets = d[\"offsets\"].numpy()\n",
    "\n",
    "        ids = ids.to(device, dtype=torch.long)\n",
    "        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "        mask = mask.to(device, dtype=torch.long)\n",
    "        targets_start = targets_start.to(device, dtype=torch.long)\n",
    "        targets_end = targets_end.to(device, dtype=torch.long)\n",
    "\n",
    "        # Predict start and end logits for each of the five models\n",
    "        outputs_start, outputs_end = model1(\n",
    "            ids=ids,\n",
    "            mask=mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        \n",
    "        # Apply softmax to the predicted start and end logits\n",
    "        outputs_start = torch.softmax(outputs_start, dim=1).cpu().detach().numpy()\n",
    "        outputs_end = torch.softmax(outputs_end, dim=1).cpu().detach().numpy()\n",
    "        \n",
    "         # Convert the start and end scores to actual predicted spans (in string form)\n",
    "        for px, tweet in enumerate(orig_tweet):\n",
    "            selected_tweet = orig_selected[px]\n",
    "            tweet_sentiment = sentiment[px]\n",
    "            _, output_sentence = calculate_jaccard_score(\n",
    "                original_tweet=tweet,\n",
    "                target_string=selected_tweet,\n",
    "                sentiment_val=tweet_sentiment,\n",
    "                idx_start=np.argmax(outputs_start[px, :]),\n",
    "                idx_end=np.argmax(outputs_end[px, :]),\n",
    "                offsets=offsets[px]\n",
    "            )\n",
    "            final_output.append(output_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(selected):\n",
    "    return \" \".join(set(selected.lower().split()))\n",
    "\n",
    "sample = pd.read_csv('./sample_submission.csv')\n",
    "sample['selected_text'] = final_output\n",
    "\n",
    "# little trick\n",
    "sample.selected_text = sample.selected_text.map(post_process)\n",
    "sample.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>selected_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>last the session day of http://twitpic.com/67ezh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>a shame! such</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>bday! happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>like i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3529</th>\n",
       "      <td>e5f0e6ef4b</td>\n",
       "      <td>tired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3530</th>\n",
       "      <td>416863ce47</td>\n",
       "      <td>thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3531</th>\n",
       "      <td>6332da480c</td>\n",
       "      <td>depression...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3532</th>\n",
       "      <td>df1baec676</td>\n",
       "      <td>i love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3533</th>\n",
       "      <td>469e15c5a8</td>\n",
       "      <td>cute</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3534 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          textID                                     selected_text\n",
       "0     f87dea47db  last the session day of http://twitpic.com/67ezh\n",
       "1     96d74cb729                                              good\n",
       "2     eee518ae67                                     a shame! such\n",
       "3     01082688c6                                       bday! happy\n",
       "4     33987a8ee5                                            like i\n",
       "...          ...                                               ...\n",
       "3529  e5f0e6ef4b                                             tired\n",
       "3530  416863ce47                                            thanks\n",
       "3531  6332da480c                                     depression...\n",
       "3532  df1baec676                                            i love\n",
       "3533  469e15c5a8                                              cute\n",
       "\n",
       "[3534 rows x 2 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 96])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ -6.0773,  -8.0240,  -7.7906,  -6.8870,   6.7060,  -2.1550,  -2.2384,\n",
       "          -1.4378,   1.0027,  -6.3535,  -7.5931,  -5.0319,  -3.5826,  -6.9654,\n",
       "          -6.3174,  -3.3022,  -2.3374,  -5.7310,  -6.2319,  -4.3736,  -3.3544,\n",
       "          -9.0867,  -9.6648,  -9.6648,  -9.6648,  -9.6648,  -9.6648,  -9.6648,\n",
       "          -9.6648,  -9.6648,  -9.6648,  -9.6648,  -9.6648,  -9.6648,  -9.6648,\n",
       "          -9.6648,  -9.6648,  -9.6648,  -9.6648,  -9.6648,  -9.6648,  -9.6648,\n",
       "          -9.6648,  -9.6648,  -9.6648,  -9.6648,  -9.6648,  -9.6648,  -9.6648,\n",
       "          -9.6648,  -9.6648,  -9.6648,  -9.6648,  -9.6648,  -9.6648,  -9.6648,\n",
       "          -9.6648,  -9.6648,  -9.6648,  -9.6648,  -9.6648,  -9.6648,  -9.6648,\n",
       "          -9.6648,  -9.6648,  -9.6648,  -9.6648,  -9.6648,  -9.6648,  -9.6648,\n",
       "          -9.6648,  -9.6648,  -9.6648,  -9.6648,  -9.6648,  -9.6648,  -9.6648,\n",
       "          -9.6648,  -9.6648,  -9.6648,  -9.6648,  -9.6648,  -9.6648,  -9.6648,\n",
       "          -9.6648,  -9.6648,  -9.6648,  -9.6648,  -9.6648,  -9.6648,  -9.6648,\n",
       "          -9.6648,  -9.6648,  -9.6648,  -9.6648,  -9.6648],\n",
       "        [ -4.8742, -10.2608,  -9.6716,  -8.9484,   3.7637,  -1.4008,  -0.4876,\n",
       "           0.9357,   2.5723,   4.7321,   4.1619,   5.9174,   0.2223,   0.8625,\n",
       "           0.3478,  -3.1073,  -4.7275,  -2.5977,  -2.6963,  -3.8258,  -3.4260,\n",
       "          -3.3291,  -9.9830, -10.7753, -10.7753, -10.7753, -10.7753, -10.7753,\n",
       "         -10.7753, -10.7753, -10.7753, -10.7753, -10.7753, -10.7753, -10.7753,\n",
       "         -10.7753, -10.7753, -10.7753, -10.7753, -10.7753, -10.7753, -10.7753,\n",
       "         -10.7753, -10.7753, -10.7753, -10.7753, -10.7753, -10.7753, -10.7753,\n",
       "         -10.7753, -10.7753, -10.7753, -10.7753, -10.7753, -10.7753, -10.7753,\n",
       "         -10.7753, -10.7753, -10.7753, -10.7753, -10.7753, -10.7753, -10.7753,\n",
       "         -10.7753, -10.7753, -10.7753, -10.7753, -10.7753, -10.7753, -10.7753,\n",
       "         -10.7753, -10.7753, -10.7753, -10.7753, -10.7753, -10.7753, -10.7753,\n",
       "         -10.7753, -10.7753, -10.7753, -10.7753, -10.7753, -10.7753, -10.7753,\n",
       "         -10.7753, -10.7753, -10.7753, -10.7753, -10.7753, -10.7753, -10.7753,\n",
       "         -10.7753, -10.7753, -10.7753, -10.7753, -10.7753],\n",
       "        [ -5.0761, -10.5193,  -9.7382,  -9.2024,   2.7857,  -5.4090,  -6.4724,\n",
       "          -6.0290,  -6.6052,  -5.0871,   0.1744,   3.0053,   5.7411,  -2.2617,\n",
       "          -3.2393,  -1.0559,   0.7069,   1.2551,  -1.2676,   1.5150,  -2.3914,\n",
       "           0.7552,   0.0124,   1.2173,  -1.1187,  -5.3220,  -1.2097,   0.6114,\n",
       "           1.3315,  -0.2433,  -0.2585,  -3.7330,  -2.2557,  -1.5148,  -9.6513,\n",
       "         -10.5597, -10.5597, -10.5597, -10.5597, -10.5597, -10.5597, -10.5597,\n",
       "         -10.5597, -10.5597, -10.5597, -10.5597, -10.5597, -10.5597, -10.5597,\n",
       "         -10.5597, -10.5597, -10.5597, -10.5597, -10.5597, -10.5597, -10.5597,\n",
       "         -10.5597, -10.5597, -10.5597, -10.5597, -10.5597, -10.5597, -10.5597,\n",
       "         -10.5597, -10.5597, -10.5597, -10.5597, -10.5597, -10.5597, -10.5597,\n",
       "         -10.5597, -10.5597, -10.5597, -10.5597, -10.5597, -10.5597, -10.5597,\n",
       "         -10.5597, -10.5597, -10.5597, -10.5597, -10.5597, -10.5597, -10.5597,\n",
       "         -10.5597, -10.5597, -10.5597, -10.5597, -10.5597, -10.5597, -10.5597,\n",
       "         -10.5597, -10.5597, -10.5597, -10.5597, -10.5597],\n",
       "        [ -5.0332, -10.4483,  -9.6891,  -9.2387,   2.8065,  -2.4178,  -2.9165,\n",
       "          -3.2330,   0.3162,   2.6597,   4.4225,   1.7702,   1.0405,   2.3725,\n",
       "           4.3328,   1.9016,   4.9492,  -0.8937,  -1.7541,  -4.5275,  -6.0290,\n",
       "          -3.3304,  -3.4593,  -5.1872,  -1.7516, -10.1317, -10.7188, -10.7188,\n",
       "         -10.7188, -10.7188, -10.7188, -10.7188, -10.7188, -10.7188, -10.7188,\n",
       "         -10.7188, -10.7188, -10.7188, -10.7188, -10.7188, -10.7188, -10.7188,\n",
       "         -10.7188, -10.7188, -10.7188, -10.7188, -10.7188, -10.7188, -10.7188,\n",
       "         -10.7188, -10.7188, -10.7188, -10.7188, -10.7188, -10.7188, -10.7188,\n",
       "         -10.7188, -10.7188, -10.7188, -10.7188, -10.7188, -10.7188, -10.7188,\n",
       "         -10.7188, -10.7188, -10.7188, -10.7188, -10.7188, -10.7188, -10.7188,\n",
       "         -10.7188, -10.7188, -10.7188, -10.7188, -10.7188, -10.7188, -10.7188,\n",
       "         -10.7188, -10.7188, -10.7188, -10.7188, -10.7188, -10.7188, -10.7188,\n",
       "         -10.7188, -10.7188, -10.7188, -10.7188, -10.7188, -10.7188, -10.7188,\n",
       "         -10.7188, -10.7188, -10.7188, -10.7188, -10.7188],\n",
       "        [ -4.5326, -10.2583,  -9.7765,  -9.2634,   0.4848,  -1.7379,  -0.0766,\n",
       "           1.4806,  -4.6618,  -4.2447,  -4.6214,  -4.8127,  -4.3697,  -3.8848,\n",
       "          -3.6136,   1.2673,   4.2053,   5.9720,   5.2678,  -2.0198,  -1.0952,\n",
       "          -0.4965,  -9.5707, -10.7375, -10.7375, -10.7375, -10.7375, -10.7375,\n",
       "         -10.7375, -10.7375, -10.7375, -10.7375, -10.7375, -10.7375, -10.7375,\n",
       "         -10.7375, -10.7375, -10.7375, -10.7375, -10.7375, -10.7375, -10.7375,\n",
       "         -10.7375, -10.7375, -10.7375, -10.7375, -10.7375, -10.7375, -10.7375,\n",
       "         -10.7375, -10.7375, -10.7375, -10.7375, -10.7375, -10.7375, -10.7375,\n",
       "         -10.7375, -10.7375, -10.7375, -10.7375, -10.7375, -10.7375, -10.7375,\n",
       "         -10.7375, -10.7375, -10.7375, -10.7375, -10.7375, -10.7375, -10.7375,\n",
       "         -10.7375, -10.7375, -10.7375, -10.7375, -10.7375, -10.7375, -10.7375,\n",
       "         -10.7375, -10.7375, -10.7375, -10.7375, -10.7375, -10.7375, -10.7375,\n",
       "         -10.7375, -10.7375, -10.7375, -10.7375, -10.7375, -10.7375, -10.7375,\n",
       "         -10.7375, -10.7375, -10.7375, -10.7375, -10.7375],\n",
       "        [ -4.7336, -10.2831,  -9.7683,  -9.6371,   1.0372,  -3.1855,  -4.8995,\n",
       "          -6.6338,  -6.7715,  -6.5440,  -6.2437,  -5.3881,  -4.7784,  -4.4684,\n",
       "          -4.4927,  -2.3882,   2.3527,   5.0244,   1.6594,   2.0435,   4.3605,\n",
       "           5.1628,  -2.3326,  -1.6895,  -2.7414,  -1.9251,  -0.5086,  -9.4374,\n",
       "         -10.6450, -10.6450, -10.6450, -10.6450, -10.6450, -10.6450, -10.6450,\n",
       "         -10.6450, -10.6450, -10.6450, -10.6450, -10.6450, -10.6450, -10.6450,\n",
       "         -10.6450, -10.6450, -10.6450, -10.6450, -10.6450, -10.6450, -10.6450,\n",
       "         -10.6450, -10.6450, -10.6450, -10.6450, -10.6450, -10.6450, -10.6450,\n",
       "         -10.6450, -10.6450, -10.6450, -10.6450, -10.6450, -10.6450, -10.6450,\n",
       "         -10.6450, -10.6450, -10.6450, -10.6450, -10.6450, -10.6450, -10.6450,\n",
       "         -10.6450, -10.6450, -10.6450, -10.6450, -10.6450, -10.6450, -10.6450,\n",
       "         -10.6450, -10.6450, -10.6450, -10.6450, -10.6450, -10.6450, -10.6450,\n",
       "         -10.6450, -10.6450, -10.6450, -10.6450, -10.6450, -10.6450, -10.6450,\n",
       "         -10.6450, -10.6450, -10.6450, -10.6450, -10.6450]], device='cuda:0')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(outputs_start.shape)\n",
    "outputs_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
